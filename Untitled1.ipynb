{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be447d97-671b-4273-8126-8c172c9139fe",
   "metadata": {},
   "source": [
    "Read all files, write them to one single toch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98f81550-e872-4270-a071-6394ba9e815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Set, Dict, Tuple, Optional, Any\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import math \n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus, relu\n",
    "from torch.distributions import Distribution, Normal\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from gmfpp.utils.data_preparation import *\n",
    "from gmfpp.utils.data_transformers import *\n",
    "from gmfpp.utils.plotting import *\n",
    "\n",
    "from gmfpp.models.ReparameterizedDiagonalGaussian import *\n",
    "from gmfpp.models.CytoVariationalAutoencoder import *\n",
    "from gmfpp.models.VariationalAutoencoder import *\n",
    "from gmfpp.models.ConvVariationalAutoencoder import *\n",
    "from gmfpp.models.VariationalInference import *\n",
    "from gmfpp.utils.utils import *\n",
    "from gmfpp.models.LoadModels import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b466df5b-0667-40a2-b3d8-783cc3b36e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:42:54 | loaded metadata\n"
     ]
    }
   ],
   "source": [
    "#path = get_server_directory_path()\n",
    "path = \"data/all/\"\n",
    "outpath = \"data/all_h5/\"\n",
    "create_directory(outpath)\n",
    "\n",
    "metadata = read_metadata(path + \"metadata.csv\")\n",
    "#metadata = metadata[:100] # @TODO: figure what to do loading the imabes below gets _very_ slow after 50_000 images\n",
    "cprint(\"loaded metadata\")\n",
    "relative_paths = get_relative_image_paths(metadata)\n",
    "image_paths = [path + relative for relative in relative_paths]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c44536-9654-4c45-8d8e-4960bab4cbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(paths: List[str], verbose: bool = False, log_every: int = 10_000):\n",
    "    image_0 = load_image(paths[0])\n",
    "    \n",
    "    dims = [len(paths)] + list(image_0.shape)\n",
    "    result = np.zeros(dims)\n",
    "    \n",
    "    for i, path in enumerate(paths):\n",
    "        image = load_image(path)\n",
    "        result[i] = image\n",
    "    \n",
    "        if verbose:\n",
    "            if i % log_every == 0:\n",
    "                cprint(\"loaded {}/{} images ({:.2f}%).\".format(i, len(paths), i  / len(paths) * 100))\n",
    "\n",
    "    if verbose:\n",
    "        cprint(\"loaded {}/{} images ({:.2f}%).\".format(len(paths), len(paths), 100))\n",
    "        \n",
    "    return result\n",
    "    \n",
    "def load_image(path: str) -> torch.Tensor:\n",
    "    return np.array(np.load(path)-20000, dtype=np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992aba7f-ef62-4ec8-bb2d-17670eb02d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:43:01 | loading images\n",
      "20:43:01 | loaded 0/488396 images (0.00%).\n",
      "20:43:04 | loaded 10000/488396 images (2.05%).\n",
      "20:43:07 | loaded 20000/488396 images (4.10%).\n",
      "20:43:10 | loaded 30000/488396 images (6.14%).\n",
      "20:43:13 | loaded 40000/488396 images (8.19%).\n",
      "20:43:16 | loaded 50000/488396 images (10.24%).\n",
      "20:43:19 | loaded 60000/488396 images (12.29%).\n",
      "20:43:22 | loaded 70000/488396 images (14.33%).\n",
      "20:43:25 | loaded 80000/488396 images (16.38%).\n",
      "20:43:28 | loaded 90000/488396 images (18.43%).\n",
      "20:43:31 | loaded 100000/488396 images (20.48%).\n",
      "20:43:34 | loaded 110000/488396 images (22.52%).\n",
      "20:43:37 | loaded 120000/488396 images (24.57%).\n",
      "20:43:40 | loaded 130000/488396 images (26.62%).\n",
      "20:43:44 | loaded 140000/488396 images (28.67%).\n",
      "20:43:47 | loaded 150000/488396 images (30.71%).\n",
      "20:43:50 | loaded 160000/488396 images (32.76%).\n",
      "20:43:53 | loaded 170000/488396 images (34.81%).\n",
      "20:43:56 | loaded 180000/488396 images (36.86%).\n",
      "20:44:00 | loaded 190000/488396 images (38.90%).\n",
      "20:44:03 | loaded 200000/488396 images (40.95%).\n",
      "20:44:06 | loaded 210000/488396 images (43.00%).\n",
      "20:44:09 | loaded 220000/488396 images (45.05%).\n",
      "20:44:13 | loaded 230000/488396 images (47.09%).\n",
      "20:44:16 | loaded 240000/488396 images (49.14%).\n",
      "20:44:19 | loaded 250000/488396 images (51.19%).\n",
      "20:44:23 | loaded 260000/488396 images (53.24%).\n",
      "20:44:27 | loaded 270000/488396 images (55.28%).\n",
      "20:44:30 | loaded 280000/488396 images (57.33%).\n",
      "20:44:34 | loaded 290000/488396 images (59.38%).\n",
      "20:44:38 | loaded 300000/488396 images (61.43%).\n",
      "20:44:41 | loaded 310000/488396 images (63.47%).\n",
      "20:44:45 | loaded 320000/488396 images (65.52%).\n",
      "20:44:49 | loaded 330000/488396 images (67.57%).\n",
      "20:44:52 | loaded 340000/488396 images (69.62%).\n",
      "20:44:56 | loaded 350000/488396 images (71.66%).\n",
      "20:44:59 | loaded 360000/488396 images (73.71%).\n",
      "20:45:03 | loaded 370000/488396 images (75.76%).\n",
      "20:45:07 | loaded 380000/488396 images (77.81%).\n",
      "20:45:10 | loaded 390000/488396 images (79.85%).\n",
      "20:45:14 | loaded 400000/488396 images (81.90%).\n",
      "20:45:18 | loaded 410000/488396 images (83.95%).\n",
      "20:45:22 | loaded 420000/488396 images (86.00%).\n",
      "20:45:26 | loaded 430000/488396 images (88.04%).\n",
      "20:45:30 | loaded 440000/488396 images (90.09%).\n",
      "20:45:34 | loaded 450000/488396 images (92.14%).\n",
      "20:45:37 | loaded 460000/488396 images (94.19%).\n",
      "20:45:40 | loaded 470000/488396 images (96.23%).\n",
      "20:45:44 | loaded 480000/488396 images (98.28%).\n",
      "20:45:47 | loaded 488396/488396 images (100.00%).\n"
     ]
    }
   ],
   "source": [
    "cprint(\"loading images\")\n",
    "images = load_images(image_paths, verbose=True, log_every=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c8f3508-03a2-49a4-b4d5-a39d67f264fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:35:08 | saving images\n",
      "19:40:43 | saved images\n"
     ]
    }
   ],
   "source": [
    "cprint(\"saving images\")\n",
    "np.save(images, outpath + 'images.npy')\n",
    "cprint(\"saved images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e446f0-62f9-4a3f-9e03-519682af60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dff700f-3ad6-4708-a8ac-d675a85f8b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:41:01 | loading images\n",
      "19:41:15 | loaded images\n"
     ]
    }
   ],
   "source": [
    "cprint(\"loading images\")\n",
    "images = torch.load(outpath + 'images.pt', map_location=torch.device('cpu'))\n",
    "cprint(\"loaded images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf1476-516b-40cb-9328-186005b0106d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
